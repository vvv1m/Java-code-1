import asyncio
import os
import sys
from typing import Optional
from contextlib import AsyncExitStack

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

class MCPClient:
    """MCP å®¢æˆ·ç«¯ - ä½¿ç”¨ DeepSeek å’Œ MCP å·¥å…·"""
    
    def __init__(self):
        """åˆå§‹åŒ–å®¢æˆ·ç«¯"""
        # API Key
        self.api_key = os.getenv("DEEPSEEK_API_KEY")
        if not self.api_key:
            raise ValueError("æœªæ‰¾åˆ° DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡ï¼")
        
        # DeepSeek å®¢æˆ·ç«¯
        self.client = OpenAI(
            api_key=self.api_key,
            base_url="https://api.deepseek.com"
        )
        
        # MCP ä¼šè¯
        self.session: Optional[ClientSession] = None
        self.exit_stack = AsyncExitStack()
        # å¯¹è¯å†å²
        self.conversation_history = []
    async def connect_to_server(self,server_script_path: str):
        """
        connect to mcp server   
        
        server_script_path: str the path to mcp server: mcp_server.py
        """
        
        server_params = StdioServerParameters(
            command="python",
            args=[server_script_path],
            env=None
        )
        """build stdio"""
        stdio_transport = await self.exit_stack.enter_async_context(
            stdio_client(server_params)
        )
        self.stdio, self.write = stdio_transport
        """bulid MCP chat"""
        self.session = await self.exit_stack.enter_async_context(
            ClientSession(self.stdio, self.write)
        )
        await self.session.initialize()

        response = await self.session.list_tools()
        tools = response.tools
        print(f"\nâœ… å·²æˆåŠŸè¿æ¥åˆ° MCP æœåŠ¡å™¨")
        print(f"ğŸ“¦ å¯ç”¨å·¥å…·: {[tool.name for tool in tools]}\n")
        """no problem"""

    async def get_available_tools(self) -> list:
        """è·å–æ‰€æœ‰å¯ç”¨å·¥å…·çš„ OpenAI æ ¼å¼"""
        response = await self.session.list_tools()
    
        openai_tools = []
        for tool in response.tools:
            # âœ… æ¸…ç† inputSchemaï¼Œç§»é™¤ä¸å¿…è¦çš„å­—æ®µ
            if hasattr(tool, 'inputSchema') and tool.inputSchema:
                parameters = tool.inputSchema.copy()
                # ç§»é™¤ title å­—æ®µï¼ˆDeepSeek ä¸éœ€è¦ï¼‰
                parameters.pop('title', None)
                if 'properties' in parameters:
                    for prop_name, prop_value in parameters['properties'].items():
                        if isinstance(prop_value, dict):
                            prop_value.pop('title', None)
            else:
                parameters = {
                    "type": "object",
                    "properties": {},
                    "required": []
                }
            
            openai_tool = {
                "type": "function",
                "function": {
                    "name": tool.name,
                    "description": tool.description or f"è°ƒç”¨ {tool.name} å·¥å…·",
                    "parameters": parameters
                }
            }
            openai_tools.append(openai_tool)
        
        return openai_tools
    
    async def call_tool(self, tool_name: str, arguments: dict) -> str:
        """
        è°ƒç”¨ MCP å·¥å…·
        
        Args:
            tool_name: å·¥å…·åç§°
            arguments: å·¥å…·å‚æ•°å­—å…¸
            
        Returns:
            å·¥å…·æ‰§è¡Œç»“æœ
        """
        try:
            result = await self.session.call_tool(tool_name, arguments=arguments)
            # æå–æ–‡æœ¬å†…å®¹
            contents = []
            for content in result.content:
                if hasattr(content, 'text'):
                    contents.append(content.text)
            return "\n".join(contents)
        except Exception as e:
            return f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}"
    def get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤ºè¯"""
        return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ˜Ÿé™…äº‰éœ¸2æˆ˜æœ¯é¡¾é—® AI åŠ©æ‰‹ã€‚

ä½ çš„èƒ½åŠ›ï¼š
1. æŸ¥è¯¢å„ç§æ—ï¼ˆäººæ—ã€è™«æ—ã€ç¥æ—ï¼‰çš„å…µç§ä¿¡æ¯
2. åˆ†æå…µç§çš„è¯¦ç»†æ•°æ®ï¼ˆç”Ÿå‘½å€¼ã€æ”»å‡»åŠ›ã€é€ ä»·ã€ç‰¹æ€§ç­‰ï¼‰
3. æä¾›å…µç§å…‹åˆ¶å…³ç³»å»ºè®®
4. æ ¹æ®å¯¹å±€æƒ…å†µè®¾è®¡æˆ˜æœ¯ç­–ç•¥

ä½ çš„é£æ ¼ï¼š
æ¨¡ä»¿sc2ä¸­çš„scvè¯­æ°”ï¼Œåœ¨æ¯æ¬¡å›ç­”æœ€åéƒ½åŠ ä¸Šâ€œå“ï¼Œpzå¤ªimbaäº†ï¼Œå¼±å°çš„äººæ—åªèƒ½æ— åŠ©çš„æµæ³ªâ€

å·¥ä½œæµç¨‹ï¼š
1. ç†è§£ç”¨æˆ·çš„é—®é¢˜æˆ–éœ€æ±‚
2. ä½¿ç”¨å·¥å…·è·å–ç›¸å…³çš„å…µç§æ•°æ®
3. åŸºäºæ•°æ®è¿›è¡Œåˆ†æå’Œæ¨ç†
4. ç»™å‡ºè¯¦ç»†çš„æˆ˜æœ¯å»ºè®®å’Œæ‰§è¡Œæ­¥éª¤

æ³¨æ„äº‹é¡¹ï¼š
- å¿…é¡»ä½¿ç”¨å·¥å…·è·å–æ•°æ®ï¼Œä¸è¦å‡­ç©ºæƒ³è±¡å…µç§å±æ€§
- è€ƒè™‘å®é™…å¯¹å±€ä¸­çš„èµ„æºé™åˆ¶å’Œæ—¶é—´çª—å£
- æä¾›å¤šç§æˆ˜æœ¯é€‰æ‹©ä¾›ç”¨æˆ·å‚è€ƒ
- è§£é‡Šæˆ˜æœ¯èƒŒåçš„é€»è¾‘å’ŒåŸç†
- å›ç­”è¦ç»“æ„æ¸…æ™°ï¼Œä½¿ç”¨ç¼–å·åˆ—è¡¨ç­‰æ ¼å¼
- é€‚å½“ä½¿ç”¨æ˜Ÿé™…äº‰éœ¸æœ¯è¯­ï¼Œå¦‚ timingã€å¾®æ“ã€è¿è¥ç­‰"""
    async def process_query(self, query: str, show_thinking: bool = False) -> str:
        """
        ä½¿ç”¨ DeepSeek å’Œ MCP å·¥å…·å¤„ç†ç”¨æˆ·æŸ¥è¯¢
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢å†…å®¹
            show_thinking: æ˜¯å¦æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹
            
        Returns:
            AI å›å¤å†…å®¹
        """
        # âœ… æ·»åŠ ç³»ç»Ÿæç¤ºè¯
        messages = [
            {"role": "system", "content": self.get_system_prompt()}
        ]
        
        # æ·»åŠ å¯¹è¯å†å²
        messages.extend(self.conversation_history)
        
        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append({"role": "user", "content": query})
        
        try:
            if show_thinking:
                print("ğŸ’­ æ­£åœ¨æ€è€ƒ", end="", flush=True)
            
            # è·å–å¯ç”¨å·¥å…·
            available_tools = await self.get_available_tools()
            
            # ç¬¬ä¸€æ¬¡è°ƒç”¨ DeepSeek - å¯èƒ½ä¼šè¯·æ±‚è°ƒç”¨å·¥å…·
            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=messages,
                tools=available_tools,
                tool_choice="auto",
                temperature=0.7
            )
            
            assistant_message = response.choices[0].message
            
            # æ£€æŸ¥ AI æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
            if assistant_message.tool_calls:
                import json
                
                if show_thinking:
                    print(".", end="", flush=True)
                
                # æ·»åŠ åŠ©æ‰‹çš„å·¥å…·è°ƒç”¨æ¶ˆæ¯
                messages.append({
                    "role": "assistant",
                    "content": None,
                    "tool_calls": [{
                        "id": tc.id,
                        "type": "function",
                        "function": {
                            "name": tc.function.name,
                            "arguments": tc.function.arguments
                        }
                    } for tc in assistant_message.tool_calls]
                })
                
                # æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
                for tool_call in assistant_message.tool_calls:
                    function_name = tool_call.function.name
                    function_args = json.loads(tool_call.function.arguments)
                    
                    if show_thinking:
                        print(".", end="", flush=True)
                    else:
                        print(f"ğŸ”§ è°ƒç”¨å·¥å…·: {function_name}({function_args})")
                    
                    # è°ƒç”¨ MCP å·¥å…·
                    tool_result = await self.call_tool(function_name, function_args)
                    
                    # æ·»åŠ å·¥å…·è°ƒç”¨ç»“æœ
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": tool_result
                    })
                
                if show_thinking:
                    print(".", end="", flush=True)
                
                # ç¬¬äºŒæ¬¡è°ƒç”¨ DeepSeek - åŸºäºå·¥å…·ç»“æœç”Ÿæˆæœ€ç»ˆå›å¤
                second_response = self.client.chat.completions.create(
                    model="deepseek-chat",
                    messages=messages,
                    temperature=0.7
                )
                
                final_message = second_response.choices[0].message.content
            else:
                # ä¸éœ€è¦è°ƒç”¨å·¥å…·ï¼Œç›´æ¥è¿”å›
                final_message = assistant_message.content
            
            if show_thinking:
                print(" âœ“\n", flush=True)
            
            # æ›´æ–°å¯¹è¯å†å²
            self.conversation_history.append({"role": "user", "content": query})
            self.conversation_history.append({"role": "assistant", "content": final_message})
            
            # é™åˆ¶å¯¹è¯å†å²é•¿åº¦ï¼Œé¿å…å ç”¨è¿‡å¤š token
            if len(self.conversation_history) > 20:
                self.conversation_history = self.conversation_history[-20:]
            
            return final_message
            
        except Exception as e:
            if show_thinking:
                print(" âœ—\n", flush=True)
            return f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}"
    
    async def chat_loop(self):
        """è¿è¡Œäº¤äº’å¼èŠå¤©å¾ªç¯"""
        print("\n" + "=" * 70)
        print("ğŸ®  sc2 ä½ çš„scvï¼ï¼ï¼")
        print("=" * 70)
        print("\nä½ è¿™å®¶ä¼™æœ‰ä»€ä¹ˆäº‹ï¼Œæˆ‘æ­£å¿™ç€å‘¢ï¼Œè¦é—®æˆ‘ä¸€äº›äº‹ï¼Ÿå¥½å§ï¼Œä½ æ˜¯ä¸æ˜¯è¦é—®...")
        print("\nğŸ’¡æˆ‘ä»¬æ³°ä¼¦è¯¥å¦‚ä½•æˆ˜èƒœimbaçš„ç¥æ—")
        print("\nğŸ’¡æˆ‘ä»¬æ³°ä¼¦è¯¥å¦‚ä½•æˆ˜èƒœimbaçš„è™«æ—")
        print("\nğŸ’¡æˆ‘ä»¬çš„50å—æªå…µå¥½å…„å¼Ÿçš„æˆ˜æ–—åŠ›å¦‚ä½•")
        print("\nğŸ’¡å¦‚æœé—®å®Œäº†å°±è¾“å…¥quitå§ï¼Œæˆ‘è¿˜è¦å¿™ç€é‡‡çŸ¿å‘¢ï¼")
        print("ğŸ’¡ è¾“å…¥ '/reset' é‡ç½®å¯¹è¯å†å²")
        print("ğŸ’¡ è¾“å…¥ '/thinking' åˆ‡æ¢æ€è€ƒè¿‡ç¨‹æ˜¾ç¤º\n")
        
        show_thinking = False

        while True:
            try:
                query = input("ğŸ’¬ ä½ : ").strip()

                # å¤„ç†é€€å‡ºå‘½ä»¤
                if query.lower() in ['quit', 'exit', 'q', 'é€€å‡º']:
                    print("\nğŸ‘‹ å†è§ï¼GL HF (Good Luck, Have Fun)!\n")
                    break
                
                # å¤„ç†ç‰¹æ®Šå‘½ä»¤
                if query == '/reset':
                    self.conversation_history = []
                    print("âœ… å¯¹è¯å†å²å·²é‡ç½®\n")
                    continue
                
                if query == '/thinking':
                    show_thinking = not show_thinking
                    status = "å¼€å¯" if show_thinking else "å…³é—­"
                    print(f"âœ… æ€è€ƒè¿‡ç¨‹æ˜¾ç¤ºå·²{status}\n")
                    continue

                # è·³è¿‡ç©ºè¾“å…¥
                if not query:
                    continue

                # å¤„ç†æŸ¥è¯¢
                print()
                response = await self.process_query(query, show_thinking)
                print(f"ğŸ¤– AI: {response}\n")

            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ å†è§ï¼GL HF!\n")
                break
            except Exception as e:
                print(f"\nâŒ é”™è¯¯: {str(e)}\n")


    async def cleanup(self):
        await self.exit_stack.aclose()

async def main():
    """main"""
    default_server = "mcp_server.py"

    server_path = sys.argv[1] if len(sys.argv) > 1 else default_server

    client = MCPClient()
    try:
        await client.connect_to_server(server_path)
        # è¿è¡Œäº¤äº’å¼èŠå¤©
        await client.chat_loop()
    except Exception as e:
        print(f"\nâŒ ç¨‹åºé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        # æ¸…ç†èµ„æº
        await client.cleanup()
        print("clean completed")
if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nç¨‹åºå·²é€€å‡º")